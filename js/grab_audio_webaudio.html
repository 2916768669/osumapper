<!DOCTYPE html>
<html>
	<head>
		<meta http-equiv="content-type" content="text/html; charset=utf-8" />
		<meta charset="utf-8" />
		<meta name="format-detection" content="telephone=no, email=no, address=no" />
		<title>tensorflow test</title>
		<link rel="stylesheet" type="text/css" href="ar3.css" />
        <script src="ar3.js" type="text/javascript"></script>
		<!--script src="tf.js" type="text/javascript"></script-->
		<script>
		var printedLines = 0;
		function print(...z) {
			if(printedLines > 30) {
				$I("out").value = $I("out").value.split("\n").slice(z.length).join("\n") + "\n" + z.join("    ");
			}
			else if($I("out").value.length == 0 || $I("out").value[$I("out").value.length-1] == "\n") {
				$I("out").value += z.join("    ");
				printedLines += z.length;
			}
			else {
				$I("out").value += "\n" + z.join("    ");
				printedLines += z.length;
			}
		}
		</script>
	</head>
	<body>
		<textarea id="out" style="height: 90%; width: 30%; display:block; position: absolute; top: 10px; left: 10px">
		</textarea>
		<input type="file" id="audio_input" style="margin-left: 50%">
	    <script>
			// const model = tf.sequential({
			// 	layers: [tf.layers.dense({units: 1, inputShape: [10]})]
			// });
			// model.compile({optimizer: 'sgd', loss: function(r, a) {
			// 	return tf.add(tf.square(tf.sub(r, a)), Math.random() * 100);
			// }});
			// async function trainModel() {
			// 	for (let i = 1; i < 500 ; ++i) {
			// 		const h = await model.fit(tf.randomNormal([8, 10]), tf.tensor([[1], [2], [3], [4], [1], [2], [3], [4]]), {
			// 			batchSize: 4,
			// 			epochs: 3
			// 		});
			// 		print("Loss after Epoch " + i + " : " + h.history.loss[0]);
			// 	}
			// }
			// $I("out").value = "";
			// trainModel();
			$I("audio_input").onchange = function() {
				var fp = $I("audio_input").files[0];
				var fr = new FileReader();

				fr.readAsArrayBuffer(fp);
				fr.onload = function() {
					var auc = new AudioContext();
					auc.decodeAudioData(fr.result).then(g);
					print("decode start...");
				};
			}

            setTimeout(function() {
                print("fetch start...");
                fetch("audio.wav", {
                    responseType: "arrayBuffer"
                }).then(z => z.arrayBuffer()).then(z => {
                    var auc = new AudioContext();
                    auc.decodeAudioData(z).then(g);
                    print("fetch OK, decode start...");
                })
            }, 100);
            function g(r) {
                var cdata = r.getChannelData(0);
                print(r.sampleRate);
                var newData = cdata.slice(r.sampleRate * 30, r.sampleRate * 31);
                window.nd = newData;
                print("decode end, OAC start...");

                var oac = new OfflineAudioContext({numberOfChannels: 1, length: newData.length, sampleRate: r.sampleRate});
                var buff = oac.createBuffer(1, newData.length, r.sampleRate);
                print("buffer create end...");

                buff.copyToChannel(newData, 0);
                print("copy_channel end...");

                var source = oac.createBufferSource();
                source.buffer = buff;

                var analyser = oac.createAnalyser();
                analyser.fftSize = 64;
                source.connect(analyser);
                print("analyser_connect end...");

                source.start();
                print("OAC render start...");
                oac.startRendering().then(result => {
                    var dataArray = new Float32Array(analyser.frequencyBinCount);
                    analyser.getFloatFrequencyData(dataArray);
                    print(dataArray);
                    window.da = dataArray;
                    print("OAC render end");
                });

            }
	    </script>

		<script>
			$I("out").value = "";
		</script>
	</body>
</html>