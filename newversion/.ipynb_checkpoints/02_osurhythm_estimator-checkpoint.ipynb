{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### osu!nn #2: rhythm estimator\n",
    "\n",
    "Builds up a rhythm model to estimate the rhythm using music and timing data.\n",
    "\n",
    "Synthesis of \"flowData\"\n",
    "* rhythmData x 1\n",
    "* (Audio) x 3\n",
    "* (Classifier) x 1\n",
    "\n",
    "Synthesis Time: ~5 mins\n",
    "\n",
    "Final edit: 2018/8/14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "First of all, Import the wheels.\n",
    "\n",
    "\"root\" points to the folder that stores all the .npz map data, where all files in .npz extension are read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "root = \"mapdata/\";\n",
    "\n",
    "# updated! now we can set divisor to any number (needs to be consistent with other pages)\n",
    "divisor = 4;\n",
    "\n",
    "# this is a global variable!\n",
    "time_interval = 16;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# lst file, [TICK, TIME, NOTE, IS_CIRCLE, IS_SLIDER, IS_SPINNER, IS_SLIDER_END, IS_SPINNER_END, \n",
    "#               0,    1,    2,         3,         4,          5,             6,              7,\n",
    "#            SLIDING, SPINNING, MOMENTUM, ANGULAR_MOMENTUM, EX1, EX2, EX3], length MAPTICKS\n",
    "#                  8,        9,       10,               11,  12,  13,  14,\n",
    "# wav file, [len(snapsize), MAPTICKS, 2, fft_size//4]\n",
    "def read_npz(fn):\n",
    "    with np.load(fn) as data:\n",
    "        wav_data = data[\"wav\"];\n",
    "        wav_data = np.swapaxes(wav_data, 2, 3);\n",
    "        train_data = wav_data;\n",
    "        div_source = data[\"lst\"][:, 0];\n",
    "        div_source2 = data[\"lst\"][:, 12:15];\n",
    "        div_data = np.concatenate([divisor_array(div_source), div_source2], axis=1);\n",
    "        lst_data = data[\"lst\"][:, 2:10];\n",
    "        # Change the 0/1 data to -1/1 to use tanh instead of softmax in the NN.\n",
    "        # Somehow tanh works much better than softmax, even if it is a linear combination. Maybe because it is alchemy!\n",
    "        lst_data = 2 * lst_data - 1;\n",
    "        train_labels = lst_data;\n",
    "    return train_data, div_data, train_labels;\n",
    "\n",
    "def divisor_array(t):\n",
    "    d_range = list(range(0, divisor));\n",
    "    return np.array([[int(k % divisor == d) for d in d_range] for k in t]);\n",
    "\n",
    "def read_npz_list():\n",
    "    npz_list = [];\n",
    "    for file in os.listdir(root):\n",
    "        if file.endswith(\".npz\"):\n",
    "            npz_list.append(os.path.join(root, file));\n",
    "    # reutnr npz_lsit;\n",
    "    return npz_list;\n",
    "\n",
    "def prefilter_data(train_data_unfiltered, div_data_unfiltered, train_labels_unfiltered):\n",
    "    # Filter out slider ends from the training set, since we cannot reliably decide if a slider end is on a note.\n",
    "    # Another way is to set 0.5 for is_note value, but that will break the validation algorithm.\n",
    "    # Also remove the IS_SLIDER_END, IS_SPINNER_END columns which are left to be zeros.\n",
    "\n",
    "    # Before: NOTE, IS_CIRCLE, IS_SLIDER, IS_SPINNER, IS_SLIDER_END, IS_SPINNER_END, SLIDING, SPINNING\n",
    "    #            0,         1,         2,          3,             4,              5,       6,        7\n",
    "    # After:  NOTE, IS_CIRCLE, IS_SLIDER, IS_SPINNER, SLIDING, SPINNING\n",
    "    #            0,         1,         2,          3,       4,        5\n",
    "\n",
    "    non_object_end_indices = [i for i,k in enumerate(train_labels_unfiltered) if k[4] == -1 and k[5] == -1];\n",
    "    train_data = train_data_unfiltered[non_object_end_indices];\n",
    "    div_data = div_data_unfiltered[non_object_end_indices];\n",
    "    train_labels = train_labels_unfiltered[non_object_end_indices][:, [0, 1, 2, 3, 6, 7]];\n",
    "    \n",
    "    # should be (X, 7, 32, 2) and (X, 6) in default sampling settings\n",
    "    # (X, fft_window_type, freq_point, magnitude/phase)\n",
    "    return train_data, div_data, train_labels;\n",
    "\n",
    "def preprocess_npzs(train_data_unfiltered, div_data_unfiltered, train_labels_unfiltered):\n",
    "    train_data, div_data, train_labels = prefilter_data(train_data_unfiltered, div_data_unfiltered, train_labels_unfiltered);\n",
    "    # In this version, the train data is already normalized, no need to do it again here\n",
    "#     mean = train_data.mean(axisprefilter_=0)\n",
    "#     std = train_data.std(axis=0)\n",
    "#     train_data = (train_data - np.tile(mean, (train_data.shape[0], 1,1,1))) / np.tile(std, (train_data.shape[0], 1,1,1))\n",
    "    \n",
    "    # Make time intervals from training data\n",
    "    if train_data.shape[0]%time_interval > 0:\n",
    "        train_data = train_data[:-(train_data.shape[0]%time_interval)];\n",
    "        div_data = div_data[:-(div_data.shape[0]%time_interval)];\n",
    "        train_labels = train_labels[:-(train_labels.shape[0]%time_interval)];\n",
    "    train_data2 = np.reshape(train_data, (-1, time_interval, train_data.shape[1], train_data.shape[2], train_data.shape[3]))\n",
    "    div_data2 = np.reshape(div_data, (-1, time_interval, div_data.shape[1]))\n",
    "    train_labels2 = np.reshape(train_labels, (-1, time_interval, train_labels.shape[1]))\n",
    "    return train_data2, div_data2, train_labels2;\n",
    "\n",
    "def get_data_shape():\n",
    "    for file in os.listdir(root):\n",
    "        if file.endswith(\".npz\"):\n",
    "            train_data_unfiltered, div_data_unfiltered, train_labels_unfiltered = read_npz(os.path.join(root, file));\n",
    "            train_data, div_data, train_labels = prefilter_data(train_data_unfiltered, div_data_unfiltered, train_labels_unfiltered);\n",
    "            # should be (X, 7, 32, 2) and (X, 6) in default sampling settings\n",
    "            # (X, fft_window_type, freq_point, magnitude/phase)\n",
    "            # X = 76255\n",
    "            # print(train_data.shape, train_labels.shape);\n",
    "            if train_data.shape[0] == 0:\n",
    "                continue;\n",
    "            return train_data.shape, div_data.shape, train_labels.shape;\n",
    "    print(\"cannot find npz!! using default shape\");\n",
    "    return (-1, 7, 32, 2), (-1, 3 + divisor), (-1, 6);\n",
    "\n",
    "def read_some_npzs_and_preprocess(npz_list):\n",
    "    td_list = [];\n",
    "    dd_list = [];\n",
    "    tl_list = [];\n",
    "    for fp in npz_list:\n",
    "        if fp.endswith(\".npz\"):\n",
    "            _td, _dd, _tl = read_npz(fp);\n",
    "            if _td.shape[1:] != train_shape[1:]:\n",
    "                print(\"Warning: something wrong found in {}! shape = {}\".format(fp, _td.shape));\n",
    "                continue;\n",
    "            td_list.append(_td);\n",
    "            dd_list.append(_dd);\n",
    "            tl_list.append(_tl);\n",
    "    train_data_unfiltered = np.concatenate(td_list);\n",
    "    div_data_unfiltered = np.concatenate(dd_list);\n",
    "    train_labels_unfiltered = np.concatenate(tl_list);\n",
    "    \n",
    "    train_data2, div_data2, train_labels2 = preprocess_npzs(train_data_unfiltered, div_data_unfiltered, train_labels_unfiltered);\n",
    "    return train_data2, div_data2, train_labels2;\n",
    "\n",
    "def train_test_split(train_data2, div_data2, train_labels2, test_split_count=233):\n",
    "    new_train_data = train_data2[:-test_split_count];\n",
    "    new_div_data = div_data2[:-test_split_count];\n",
    "    new_train_labels = train_labels2[:-test_split_count];\n",
    "    test_data = train_data2[-test_split_count:];\n",
    "    test_div_data = div_data2[-test_split_count:];\n",
    "    test_labels = train_labels2[-test_split_count:];\n",
    "    return (new_train_data, new_div_data, new_train_labels), (test_data, test_div_data, test_labels);\n",
    "\n",
    "# (train_data_unfiltered, div_data_unfiltered, train_labels_unfiltered) = read_all_npzs();\n",
    "\n",
    "train_file_list = read_npz_list();\n",
    "\n",
    "train_shape, div_shape, label_shape = get_data_shape();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now build the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "time_distributed_input (InputLa (None, 16, 7, 32, 2) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, 16, 6, 31, 16 144         time_distributed_input[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 16, 6, 15, 16 0           time_distributed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 16, 6, 15, 16 0           time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistrib (None, 16, 6, 15, 16 0           time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_4 (TimeDistrib (None, 16, 5, 13, 16 1552        time_distributed_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_5 (TimeDistrib (None, 16, 5, 6, 16) 0           time_distributed_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_6 (TimeDistrib (None, 16, 5, 6, 16) 0           time_distributed_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_7 (TimeDistrib (None, 16, 5, 6, 16) 0           time_distributed_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_8 (TimeDistrib (None, 16, 480)      0           time_distributed_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 16, 64)       139520      time_distributed_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, 16, 11)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 16, 75)       0           lstm[0][0]                       \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 16, 71)       5396        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 16, 71)       5112        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 16, 6)        432         dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 152,156\n",
      "Trainable params: 152,156\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model;\n",
    "\n",
    "def build_model():\n",
    "    model1 = keras.Sequential([\n",
    "        keras.layers.TimeDistributed(keras.layers.Conv2D(16, (2, 2),\n",
    "                           data_format='channels_last'),\n",
    "                           input_shape=(time_interval, train_shape[1], train_shape[2], train_shape[3])),\n",
    "        keras.layers.TimeDistributed(keras.layers.MaxPool2D((1, 2),\n",
    "                           data_format='channels_last')),\n",
    "        keras.layers.TimeDistributed(keras.layers.Activation(activation=tf.nn.relu)),\n",
    "        keras.layers.TimeDistributed(keras.layers.Dropout(0.3)),\n",
    "        keras.layers.TimeDistributed(keras.layers.Conv2D(16, (2, 3),\n",
    "                           data_format='channels_last')),\n",
    "        keras.layers.TimeDistributed(keras.layers.MaxPool2D((1, 2),\n",
    "                           data_format='channels_last')),\n",
    "        keras.layers.TimeDistributed(keras.layers.Activation(activation=tf.nn.relu)),\n",
    "        keras.layers.TimeDistributed(keras.layers.Dropout(0.3)),\n",
    "        keras.layers.TimeDistributed(keras.layers.Flatten()),\n",
    "        keras.layers.LSTM(64, activation=tf.nn.tanh, return_sequences=True)\n",
    "    ])\n",
    "    \n",
    "    input2 = keras.layers.InputLayer(input_shape=(time_interval, div_shape[1]));\n",
    "    \n",
    "    conc = keras.layers.concatenate([model1.output, input2.output]);\n",
    "    dense1 = keras.layers.Dense(71, activation=tf.nn.tanh)(conc);\n",
    "    dense2 = keras.layers.Dense(71, activation=tf.nn.relu)(dense1);\n",
    "    dense3 = keras.layers.Dense(label_shape[1], activation=tf.nn.tanh)(dense2);\n",
    "    \n",
    "\n",
    "    \n",
    "    try:\n",
    "        optimizer = tf.optimizers.RMSprop(0.001) #Adamoptimizer?\n",
    "    except:\n",
    "        optimizer = tf.train.RMSPropOptimizer(0.001) #Adamoptimizer?\n",
    "\n",
    "    \n",
    "    final_model = Model(inputs=[model1.input, input2.input], outputs=dense3);\n",
    "    final_model.compile(loss='mse',\n",
    "                optimizer=optimizer,\n",
    "                metrics=[keras.metrics.mae])\n",
    "    return final_model\n",
    "\n",
    "model = build_model()\n",
    "model.summary()\n",
    "\n",
    "def plot_history(history):\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean Abs Error [Limitless]')\n",
    "    plt.plot(history.epoch, np.array(history.history['mean_absolute_error']), \n",
    "           label='Train MAE')\n",
    "    plt.plot(history.epoch, np.array(history.history['val_mean_absolute_error']),\n",
    "           label = 'Val MAE')\n",
    "    plt.plot(history.epoch, np.array(history.history['loss']), \n",
    "           label='Train Loss')\n",
    "    plt.plot(history.epoch, np.array(history.history['val_loss']),\n",
    "           label = 'Val Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Display training progress by printing a single dot for each completed epoch.\n",
    "class PrintDot(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self,epoch,logs):\n",
    "        if epoch % 100 == 0: print('')\n",
    "        print('.', end='')\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='mean_absolute_error', patience=20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "ぐるぐる。\n",
    "\n",
    "it seems that with GPU training, \"batch_size\" must be set to a smaller value like 10 (default is 32), otherwise it will crash. probably because there is not enough GPU memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "...."
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-3652de86f6b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m     history = model.fit([new_train_data, new_div_data], new_train_labels, epochs=EPOCHS,\n\u001b[0;32m     20\u001b[0m                         \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m#batch_size=10,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m                         callbacks=[early_stop, PrintDot()])\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;31m# For development! may cause bug in some environment.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\asus\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\Pyth3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1361\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1362\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1363\u001b[1;33m           validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1365\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mC:\\Users\\asus\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\Pyth3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    262\u001b[0m           \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m           \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\asus\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\Pyth3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2912\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_arrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_symbols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2914\u001b[1;33m     \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2915\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2916\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\asus\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\Pyth3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1382\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Don't worry, it will successfully overfit after those 16 epochs.\n",
    "EPOCHS = 16\n",
    "\n",
    "# since each map npz is about 6mb, this amounts to around 1200mb of RAM.\n",
    "too_many_maps_threshold = 200\n",
    "data_split_count = 80\n",
    "\n",
    "# if there is too much data, reduce epoch count (hmm)\n",
    "if len(train_file_list) >= too_many_maps_threshold:\n",
    "    EPOCHS = 6\n",
    "\n",
    "if len(train_file_list) < too_many_maps_threshold:\n",
    "    train_data2, div_data2, train_labels2 = read_some_npzs_and_preprocess(train_file_list);\n",
    "\n",
    "    # Split some test data out\n",
    "    (new_train_data, new_div_data, new_train_labels), (test_data, test_div_data, test_labels) = train_test_split(train_data2, div_data2, train_labels2);\n",
    "\n",
    "    # Store training stats\n",
    "    history = model.fit([new_train_data, new_div_data], new_train_labels, epochs=EPOCHS,\n",
    "                        validation_split=0.2, verbose=0, #batch_size=10,\n",
    "                        callbacks=[early_stop, PrintDot()])\n",
    "\n",
    "    # For development! may cause bug in some environment.\n",
    "    plot_history(history)\n",
    "else: # too much data! read it every turn.\n",
    "    for epoch in range(EPOCHS):\n",
    "        for map_batch in range(np.ceil(len(train_file_list) / data_split_count).astype(int)): # hmmmmm\n",
    "            if map_batch == 0:\n",
    "                train_data2, div_data2, train_labels2 = read_some_npzs_and_preprocess(train_file_list[map_batch * data_split_count : (map_batch+1) * data_split_count]);\n",
    "                (new_train_data, new_div_data, new_train_labels), (test_data, test_div_data, test_labels) = train_test_split(train_data2, div_data2, train_labels2);\n",
    "            else:\n",
    "                new_train_data, new_div_data, new_train_labels = read_some_npzs_and_preprocess(train_file_list[map_batch * data_split_count : (map_batch+1) * data_split_count]);\n",
    "            \n",
    "            history = model.fit([new_train_data, new_div_data], new_train_labels, epochs=1,\n",
    "                                validation_split=0.2, verbose=0, #batch_size=10,\n",
    "                                callbacks=[])\n",
    "            # Manually print the dot\n",
    "            print('.', end='');\n",
    "        print('');\n",
    "\n",
    "[loss, mae] = model.evaluate([test_data, test_div_data], test_labels, verbose=0)\n",
    "\n",
    "print(\"\\nTesting set Mean Abs Error: {}\".format(mae))\n",
    "\n",
    "\n",
    "# print(test_predictions)\n",
    "# print(test_labels)\n",
    "# print(test_predictions - list(test_labels))\n",
    "# print(\"Mean Abs Error: \"+str(np.mean(np.abs(test_predictions - test_labels))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Print the testing accuracy of the model (using F1-score), and compare with the accuracy of a random result, then in addition print the accuracy of individual columns.\n",
    "\n",
    "For the Sota dataset, it should get around 0.6 overall score, 0.77 for is_note, and something much smaller for is_circle, is_slider and is_spinner. It may also throw a warning because there is no spinner predicted/actually present.\n",
    "\n",
    "This is not a very high accuracy - but it is not really a problem; map rhythm does not fully correlate to the music itself. There are overmaps, innovative rhythms... and we can also learn from some of them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9941351329637664\n",
      "0.9945460378569136\n",
      "0.36132577709084673\n",
      "is_note f1_score: 0.9973278520041109 from 0.5759741756974868\n",
      "is_circle f1_score: 0.9949748743718594 from 0.41940435984034385\n",
      "is_slider f1_score: 0.9966297544535387 from 0.35809654228004106\n",
      "is_spinner f1_score: 0.0 from 0.0010735373054213634\n",
      "is_sliding f1_score: 0.9940959409594097 from 0.4264432029795159\n",
      "is_spinning f1_score: 0.42857142857142855 from 0.013911182450508293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\Pyth3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "test_predictions = model.predict([test_data, test_div_data]).reshape((-1, time_interval, label_shape[1]))\n",
    "\n",
    "flat_test_preds = test_predictions.reshape(-1, label_shape[1]);\n",
    "flat_test_labels = test_labels.reshape(-1, label_shape[1]);\n",
    "\n",
    "pred_result = (np.sign(flat_test_preds) + 1) / 2\n",
    "actual_result = (flat_test_labels + 1) / 2\n",
    "\n",
    "random_result = (1 + np.sign(-1 + 2 * np.random.random(size=pred_result.shape))) / 2;\n",
    "\n",
    "is_obj_pred = (1 + np.sign(flat_test_preds[:, 0:1])) / 2;\n",
    "obj_type_pred = np.sign(flat_test_preds[:, 1:4] - np.tile(np.expand_dims(np.max(flat_test_preds[:, 1:4], axis=1), 1), (1, 3))) + 1;\n",
    "others_pred = (1 + np.sign(flat_test_preds[:, 4:label_shape[1]] + 0.5)) / 2;\n",
    "# Only predict obj_type when there is an object!\n",
    "another_pred_result = np.concatenate([is_obj_pred, is_obj_pred * obj_type_pred, others_pred], axis=1);\n",
    "print(f1_score(actual_result.flatten(), pred_result.flatten()));\n",
    "print(f1_score(actual_result.flatten(), another_pred_result.flatten()));\n",
    "print(f1_score(actual_result.flatten(), random_result.flatten()));\n",
    "\n",
    "# Individual column predictions\n",
    "column_names = [\"is_note\", \"is_circle\", \"is_slider\", \"is_spinner\", \"is_sliding\", \"is_spinning\"];\n",
    "for i, k in enumerate(column_names):\n",
    "    print(\"{} f1_score: {} from {}\".format(k, f1_score(another_pred_result[:, i], actual_result[:, i]), f1_score(random_result[:, i], actual_result[:, i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# emmmm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "出来上がり☆"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    }
   ],
   "source": [
    "tf.keras.models.save_model(\n",
    "    model,\n",
    "    \"saved_rhythm_model\",\n",
    "    overwrite=True,\n",
    "    include_optimizer=True\n",
    ");\n",
    "\n",
    "# WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer\n",
    "# state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will\n",
    "# have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
